<!doctype html>
<html>
  <head>
  
    <meta charset="utf-8">
    <meta content="IE=edge,chrome=1" http-equiv="X-UA-Compatible">

    <title>Recognition of mutation in cancer cells</title>

    <meta name="viewport" content="width=device-width, initial-scale=1.0">

   
  
    <link href="assets/css/main.css" rel="stylesheet">
    
  
  </head>
  <body>
    
    <div class="section-blog-post">
      <div class="container">
        <div class="row">
          <div class="col-sm-12">
            <div class="post-container">
              <a class="back" href="./index.html">Back to all posts</a>

              <h1>Identifying Mutation in Colorectal Cancer Cells</h1>

              <span class="by">Posted by <strong>Balaganesh</strong> on <strong>March, 2021</strong>,6-8 min read</span>
              <span style="display:block; height: 25px;"></span>
              <div class="featured-image">
                <img src="https://downloads.healthcatalyst.com/wp-content/uploads/2017/04/machine-learning-in-healthcare.jpg" width="25%", class="center_small">
              </div>
              
              <div class="post-body">
                <span style="display:block; height: 25px;"></span>
                <p>Machine learning has the potential to revolutionize the healthcare industry.
                Although it is still in its early stages, machine learning is proving to be extremely useful especially in the diagnostics department. 
                Several machine learning models were capable of defeating Stanford University radiologists in a competition designed by the Stanford Machine Learning group within the last decade.
It is only a matter of time before more complex problems, such as histopathology, see a machine learning model outperform a histopathologist. 
                </p>

                <p>
                    This project was part of my research internship at Maastricht University, Netherlands. The task at hand is to develop deep learning vision models that would be 
                    capable of identifying mutations in colorectal cancer images. Detecting the mutation is critical in patient treatment because it involves a change in the drug course or, in some cases, a completely different form of treatment.
                    Let's take a look at an example of a sample from the dataset.
                    MSIH are tumour positives, while Non MSIH are tumour negatives.
                    For the average human eye, they are virtually indistinguishable.  histopathologist use a technique called Macenko method where they use a special dye that changes the cell to a gradient of colors based on their chemical composition. A more
                    detailed explanation can be found in the project report attached to this page. 
                </p>
               
                    <img src="images/cancer-images/data.png" width="25%" class="center_small">
                    <span style="display:block; height: 25px;"></span>
                <p>
                    This is a binary image classification problem. So, let's use the sultan of computer vision, the CNN's. Convolutional neural networks are great
                    at image recognition, but they have one major problem. Scale invariance. This is an even bigger problem in histopathological image recognition because,
                    spatial coordinates are important. A single patient's imagery of a mutated cell will range somewhere from 1GB to 5GB with a spatial resolution of up to 4k pixels. 
                    It is infeasible to train with such a large image given the memory restrictions. So the approach would be to cut the single large image to smaller ones and 
                    annotate them according to their local mutation state. But what would be the best cut resolution? 256x256? 512x512? This project explores the idea of progressive resizing,
                    where instead of using one size, one can use multiple size in increasing order until it is not possible to fit in the memory anymore. progressive resizing is where
                    a CNN model is trained on the lowest image size, then the weights of this model can be used to train the next image size and so on until the final size.
                    This is sort of a peseudo transfer learning. The advantages here are 
                    <ul>
                        <li>It can overcome the scale invariance up to a degree. </li>
                        <li>Still able to leverage large scale weight database like ImagNet and popular CNN architectures like ResNet or DenseNet</li>
                        <li>Training is much faster and memory efficient than training on the largest possible scale.</li>
                        <li>The performance is much better as we will see.</li>
                    </ul>
                    <p>
                The below image is a outlay of the pipeline used in this project. After experimenting with several architectures like ResNet, InceptionV3 etc.. DenseNet proved to 
                be the best performing one. The inference to note here is that, the features of this dataset are particularly hard to learn and relatively shallow networks like ResNet 
                suffers from vanishing gradients as the depth is increased in ranges of 50,101,121 etc.. But denseNet is immune to this as it is designed by making the gradients flow 
                from any layer close to the loss function to any earlier layers, hence the resulting good performance. 
                <span style="display:block; height: 25px;"></span>
                    <img src="images/cancer-images/arch.png" width=100% class="center_large">
                  </p>
                  <span style="display:block; height: 25px;"></span>
                </p>
                    
                    
                 
                
                
                <p>
                    Lets take a look at the results. AUC metrics were used as the final measure of the predictions as the normal acccuracy is not viable since 
                    the dataset is quite imbalanced with positive cases being very and artifically upsampled. AUC give the true accuracy in this case. 
                    The results shown are the ensembled final model with AUC of 0.96 for the smaller images. Remember the training images are not the full scale image. They have to converted
                    back to their original size. To get the predictions for the patient level, all the prediction probabilites of the smaller images were averaged. 
                    The final results were, 129 patients predicted correctly, and 15 wrongly. Although not acceptable at a commercial scale, still very good results from a research standpoint.

                    <div class="img_row">
                        <div class="img_column">
                            <img src="images/cancer-images/auc_patient.png" class="center_large">
                        </div>
                        <div class="img_column">
                            <img src="images/cancer-images/patient_final.png" class="center_large">
                        </div>
                        
                      </div> 
                    
                    
                    
                </p>

                <p>
                    Now lets viualize some intersting findings from our best performing model. One of the visualization I find interesting is the class activation mapping. It can highlight the features of the image 
                    the model looks at to make a prediction. In our case, it is even better because it exactly points out which region in the spatial coordinates of the tumor, the mutation has occcured. What I inferred from this 
                    image is that the concentric circles are somewhow correlated. I cannot confirm as I am not an expert in histopathology but someone whos is might be able to. 
                    <span style="display:block; height: 25px;"></span>
                    <img src="images/cancer-images/grad-cam.png" class="center_medium">
                </p>
                <p>
                    Now lets try to plot the region of mutation occurence in the patient level image. I wanted to see if there are any patterns in the occurence of the mutation by
                    plotting the images based on their original coordinates before cut, and classifying based on the result. However, there were no underlying patterns present here,
                    maybe a larger sample size and a clustering algorithm like KNN's might be able to identify the possible patterns. 
                    <img src="images/cancer-images/nonmsih_2.PNG" class="center_medium">
                    <img src="images/cancer-images/msih_1.PNG" class="center_medium">
                    <img src="images/cancer-images/msih_2.PNG" class="center_medium">
                    
                </p>

                <p>
                    You have reached the end. This is a gist of my analysis on this problem Hope you had a good time. If you are further interested in this work, please refer the full jupyter notebook at <a href=https://github.com/balaganeshmohan/Colorectal-cancer-classification-with-histopathological-images/blob/main/CancerClassification.ipynb>link</a>
                </p>
               
              </div>

              <!-- <div class="post-author">
                <div class="headshot">
                  <img src="https://dl.dropboxusercontent.com/u/598519/chase.png" width="100%">
                </div>
                <p><strong>About the author:</strong> Chase Coleman is co-founder of ButterCMS and a developer. He loves building tools that make life easier for developers. You can find him at @buttercms and chase@buttercms.com  where he will definitely reply to you.</p>
              </div>

              <div id="disqus_thread"></div>
              <script type="text/javascript">
                  /* * * CONFIGURATION VARIABLES * * */
                  var disqus_shortname = 'buttercms';
                  
                  /* * * DON'T EDIT BELOW THIS LINE * * */
                  (function() {
                      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
                      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
                      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
                  })();
              </script>
            </div> -->
          </div>        
        </div>
      </div>
    </div>
  </body>
</html>